{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符排序\n",
    "- 目标：\n",
    "\n",
    "![](https://cdn.jsdelivr.net/gh/Jason-L-Yan/imgBed/img/image-20200706212357924.png)\n",
    "- 原理\n",
    "\n",
    "![](https://cdn.jsdelivr.net/gh/Jason-L-Yan/imgBed/img/image-20200706212750115.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "把字符进行 one-hot 编码，输入与标签维度定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1  # 一个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 2, 3]  # The input sequence is 'hello'\n",
    "y_data = [3, 1, 2, 3, 2]  # The output sequence is 'ohlol'\n",
    "\n",
    "# one-hot encoding\n",
    "# pattern 1. \n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "# pattern 2. \n",
    "# words = torch.tensor([0, 1, 2, 3], dtype=torch.long)\n",
    "# one_hot_encoding = one_hot(words)\n",
    "# print(one_hot_encoding)\n",
    "\n",
    "# Convert indices into one-hot vector\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]  # [seqLen, input_size]\n",
    "# Reshape the inputs to (seqLen, batch_size, input_size) \n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data).view(-1, 1)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 RNNCell 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.RNNcell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.RNNcell(input, hidden)\n",
    "        return hidden \n",
    "        \n",
    "    def init_hidden(self):  # provide initial hidden(h0)\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(input_size, hidden_size, batch_size)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "======================== 0 ========================\nPredicted string: ellll, Epocn [1 / 15] loss=6.7245\n======================== 1 ========================\nPredicted string: ellll, Epocn [2 / 15] loss=5.8842\n======================== 2 ========================\nPredicted string: oolll, Epocn [3 / 15] loss=5.2503\n======================== 3 ========================\nPredicted string: oholl, Epocn [4 / 15] loss=4.8773\n======================== 4 ========================\nPredicted string: oholl, Epocn [5 / 15] loss=4.5178\n======================== 5 ========================\nPredicted string: ohlll, Epocn [6 / 15] loss=4.2397\n======================== 6 ========================\nPredicted string: ohlol, Epocn [7 / 15] loss=3.9508\n======================== 7 ========================\nPredicted string: ohlol, Epocn [8 / 15] loss=3.6986\n======================== 8 ========================\nPredicted string: ohlol, Epocn [9 / 15] loss=3.5046\n======================== 9 ========================\nPredicted string: ohlol, Epocn [10 / 15] loss=3.3255\n======================== 10 ========================\nPredicted string: ohlol, Epocn [11 / 15] loss=3.1152\n======================== 11 ========================\nPredicted string: ohlol, Epocn [12 / 15] loss=2.8638\n======================== 12 ========================\nPredicted string: ohlol, Epocn [13 / 15] loss=2.6206\n======================== 13 ========================\nPredicted string: ohlol, Epocn [14 / 15] loss=2.4316\n======================== 14 ========================\nPredicted string: ohlol, Epocn [15 / 15] loss=2.2891\n"
    }
   ],
   "source": [
    "i = 0\n",
    "for epoch in range(15):\n",
    "    print('=' * 24, i, '=' * 24)\n",
    "    i += 1\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = net.init_hidden()\n",
    "    print('Predicted string: ', end='')\n",
    "    # shape of inputs:(seqLen, batch_size, input_size)\n",
    "    # shape of input :(batch_size, input_size)\n",
    "    # shape of labels:(seqLen, 1)\n",
    "    # shape of label :(1)\n",
    "    for input, label in zip(inputs, labels):  \n",
    "        hidden = net(input, hidden)\n",
    "        # 不要用loss.item()，因为一个循环只求出了一个seq的损失，要把所有seq的损失和加起来构造计算图，如上方最后一张图所示，所有seq的损失的和，才是最终的损失。\n",
    "        loss += criterion(hidden, label)  \n",
    "        _, idx = hidden.max(dim=1)  # 返回每一行最大概率的下标\n",
    "        print(idx2char[idx.item()], end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(', Epocn [%d / 15] loss=%.4f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size2 = 4\n",
    "hidden_size2 = 4\n",
    "num_layers2 = 1\n",
    "batch_size2 = 1  # 一个样本\n",
    "seq_len2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char2 = ['e', 'h', 'l', 'o']\n",
    "x_data2 = [1, 0, 2, 2, 3]  # The input sequence is 'hello'\n",
    "y_data2 = [3, 1, 2, 3, 2]  # The output sequence is 'ohlol'\n",
    "one_hot_lookup2 = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "# Convert indices into one-hot vector\n",
    "x_one_hot2 = [one_hot_lookup2[x2] for x2 in x_data2]  # [seqLen, input_size]\n",
    "# Reshape the inputs to (seqLen, batch_size, input_size) \n",
    "inputs2 = torch.Tensor(x_one_hot2).view(seq_len2, batch_size2, input_size2)\n",
    "labels2 = torch.LongTensor(y_data2)  # 不同于上一个程序，(seqLen*batch_size, 1), 呼应Model2中forward的返回值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 RNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(torch.nn.Module):\n",
    "    def __init__(self, input_size2, hidden_size2, batch_size2, num_layers2):\n",
    "        super(Model2, self).__init__()\n",
    "        self.num_layers2 = num_layers2\n",
    "        self.batch_size2 = batch_size2\n",
    "        self.input_size2 = input_size2\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.RNN = torch.nn.RNN(input_size=self.input_size2, \n",
    "                                hidden_size=self.hidden_size2,                                                                                  num_layers=self.num_layers2)\n",
    "\n",
    "    def forward(self, input2):\n",
    "        # shape of hidden:(num_layers, batch_size, hidden_size)\n",
    "        hidden2 = torch.zeros(self.num_layers2, self.batch_size2, self.hidden_size2)\n",
    "        out, _ = self.RNN(input2, hidden2)\n",
    "        return out.view(-1, self.hidden_size2)  # Reshape out to (seqLen*batch_size, hidden_size), 变成了一个矩阵，方便计算交叉熵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Model2(input_size2, hidden_size2, batch_size2, num_layers2)\n",
    "criterion2 = torch.nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.Adam(net2.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:  hoooo, Epocn [1 / 15] loss=1.584\nPredicted:  ooooo, Epocn [2 / 15] loss=1.464\nPredicted:  ooooo, Epocn [3 / 15] loss=1.366\nPredicted:  ooooo, Epocn [4 / 15] loss=1.286\nPredicted:  ooooo, Epocn [5 / 15] loss=1.224\nPredicted:  ooooo, Epocn [6 / 15] loss=1.165\nPredicted: ooooo, Epocn [7 / 15] loss=1.098\nPredicted:  ooooo, Epocn [8 / 15] loss=1.025\nPredicted:  ooooo, Epocn [9 / 15] loss=0.951\nPredicted:  ohloo, Epocn [10 / 15] loss=0.883\nPredicted:  ohloo, Epocn [11 / 15] loss=0.826\nPredicted:  ohlol, Epocn [12 / 15] loss=0.780\nPredicted:  ohlol, Epocn [13 / 15] loss=0.740\nPredicted:  ohlol, Epocn [14 / 15] loss=0.702\nPredicted:  ohlol, Epocn [15 / 15] loss=0.665\n"
    }
   ],
   "source": [
    "loss2 = 0\n",
    "for epoch in range(15):\n",
    "    optimizer2.zero_grad()\n",
    "    outputs = net2(inputs2)\n",
    "    loss2 = criterion2(outputs, labels2)\n",
    "    loss2.backward()\n",
    "    optimizer2.step()\n",
    "\n",
    "    _, idx2 = outputs.max(dim=1)\n",
    "    idx2 = idx2.data.numpy()\n",
    "    print('Predicted: ', ''.join([idx2char2[x] for x in idx2]), end='')\n",
    "    print(', Epocn [%d / 15] loss=%.3f' % (epoch + 1, loss2.item()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594168209891",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}